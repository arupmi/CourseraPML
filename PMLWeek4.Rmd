---
title: "CourseraML"
author: "Arup Mitra"
date: "2 November 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the Data

The initial setup activities related to loading the requisite libraries are carried out.
Then the data files are downloaded from the URLs provided.

This consists of a  training dataset and a 20 observations testing dataset.

```{r init}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(RGtk2)
library(rattle)
library(randomForest)

UrlTrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

destfile<-"pml-training.csv"
# download the datasets
if (!file.exists(destfile)) {
        download.file(UrlTrain,"pml-training.csv")
        download.file(UrlTest,"pml-testing.csv")
}
dt_training <- read.csv("pml-training.csv")
dt_testing  <- read.csv("pml-testing.csv")

```

## Data Cleansing

* Remove all columns that contains NA (variance, mean, SD) 
* Remove features that are not in the testing dataset.
* The testing dataset has no time-dependence, these values are useless and can be disregarded. 
* The first 7 features are also removed since they are related to the time-series or are not numeric.


```{r cleanse, echo=FALSE}
features <- names(dt_testing[,colSums(is.na(dt_testing)) == 0])[8:59]

# Only use features used in testing cases.
dt_training <- dt_training[,c(features,"classe")]
dt_testing <- dt_testing[,c(features,"problem_id")]

dim(dt_training)
dim(dt_testing)

```

## Data Partitioning

The data into a training data set (60% of the total cases) and a testing data set (40% of the total cases for allowing to estimate the out of sample error of the predictor).

```{r partition, echo=FALSE}
set.seed(12345)

inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]

dim(training)
dim(testing)

```

## Build Decision Tree Model

```{r decision, echo=FALSE}
modFitDT <- rpart(classe ~ ., data = training, method="class")
fancyRpartPlot(modFitDT)
```

## Decision Tree Predictions

```{r predict, echo=FALSE}
set.seed(12345)

prediction <- predict(modFitDT, testing, type = "class")
confusionMatrix(prediction, testing$classe)
```

## The Random Forest Model

Using random forest, the out of sample error should be small. The error will be estimated using the 40% testing sample, an error estimate of less than 3% is expected.

```{r rfmodel, echo=FALSE}
set.seed(12345)
modFitRF <- randomForest(classe ~ ., data = training, ntree = 1000)
prediction <- predict(modFitRF, testing, type = "class")
confusionMatrix(prediction, testing$classe)
```


## Prediction on Test Data

** Decision Tree Prediction

```{r testprediction, echo=FALSE}
predictionDT <- predict(modFitDT, dt_testing, type = "class")
predictionDT
```

** Random Forest Prediction

```{r rfprediction, echo=FALSE}
predictionRF <- predict(modFitRF, dt_testing, type = "class")
predictionRF
```

*** Conclusion

Based on the above analysis, it can be stated that the Random Forest Model definitely provides a much more accurate prediction for this set of data.
